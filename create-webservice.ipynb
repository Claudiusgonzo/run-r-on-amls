{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an R web service with the Azure Machine Learning services\n",
    "This notebook shows how to write and deploy a scoring webservice with Azure Machine Learning Services (AMLS) that runs R code. Note that we are not using Azure Machine Learning Studio here. Also, this shows how to run an R workload in the context of Python. It does not use any native support of R - which may come in future (or might be already there, depending on when you read this article).\n",
    "\n",
    "The underlying scenario is a **scoring** scenario. If your scenario is rather compute-intensive **batch computation**, you might rather wanna use the notebook [here](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb) as base and adopt some of the ideas contained in this notebook (eg. using rpy2). Similarly, for creating **pipelines**, you can use the samples [here](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/machine-learning-pipelines) as base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can start, you need\n",
    "\n",
    "* an Azure Machine Learning services account in Azure.\n",
    "* If deployed to AKS: an AKS cluster in Azure Machine Learning services.\n",
    "\n",
    "For brevity reasons, I do not go into details here. There is numerous examples on creating an AKS cluster for Azure Machine Learning services. The easiest way to create one is to create it through the Azure Machine Learning Workspace in Azure Portal. Besides, there are examples [here](https://github.com/Azure/MachineLearningNotebooks) as well as the option to create an AKS through the [Azure ML CLI extension](https://docs.microsoft.com/de-de/azure/machine-learning/service/reference-azure-machine-learning-cli). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this instantiates the workspace object directly.\n",
    "#       if you have a config file you also use that to get the workspace.\n",
    "import os\n",
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = \"azureml-spike-rg\"\n",
    "workspace_name = \"OurWorkspace\"\n",
    "\n",
    "workspace = Workspace(subscription_id=subscription_id,\n",
    "                      resource_group=resource_group,\n",
    "                      workspace_name=workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create/train the model\n",
    "\n",
    "See the included `create_model.r` file so see how a model could be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the model\n",
    "Register an existing trained model, add description and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model.register(model_path = \"model.RData\",\n",
    "                       model_name = \"model.RData\",\n",
    "                       tags = {'area': \"samples\", 'type': \"regression\"},\n",
    "                       description = \"A simple linear regression model to show the usage of R in Azure Machine Learning Services.\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an image\n",
    "Create an image using\n",
    "- the registered model (created and registered above),\n",
    "- a script that will load and run the model and\n",
    "- all dependencies required by the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import traceback\n",
    "import json\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "import rpy2.rinterface\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "def init():\n",
    "    # only needed if model data collection is used\n",
    "    # note: the example here uses a single model data collector. you can however use multiple ones if needed.\n",
    "    global modeldata_collector\n",
    "    modeldata_collector = ModelDataCollector(\"model.RData\", identifier=\"predictions\", feature_names=[\"x\", \"y\"])\n",
    "    \n",
    "    # note: this function is run whenever the container is started\n",
    "    # init rpy2\n",
    "    rpy2.rinterface.initr()\n",
    "    # load model\n",
    "    model_path = Model.get_model_path('model.RData')\n",
    "    robjects.r(\"load('{model_path}')\".format(model_path=model_path))\n",
    "    # run init() function in R (if exists)\n",
    "    robjects.r(\"if (exists('init', mode='function')) { init() }\")\n",
    "\n",
    "def run(input_json_string): \n",
    "    # note: this function is run whenever a scoring request has been received\n",
    "    try:\n",
    "        result_vector = robjects.r(\n",
    "                \"run('{input_json_string}')\".format(input_json_string=input_json_string)\n",
    "            )\n",
    "        if len(result_vector) > 0:\n",
    "            try:\n",
    "                # get prediction result              \n",
    "                prediction_result_json = json.loads(result_vector[0])\n",
    "                \n",
    "                # log prediction (only needed if model data is collected)\n",
    "                input_x = json.loads(input_json_string)[\"x\"]\n",
    "                prediction_y = prediction_result_json[\"y\"]\n",
    "                modeldata_collector.collect([input_x, prediction_y])\n",
    "                \n",
    "                # return prediction result\n",
    "                return prediction_result_json\n",
    "            except ValueError:\n",
    "                return {\"message\": result_vector }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {           \n",
    "            \"error\": repr(e),\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dependencies required by the scoring script to run.\n",
    "\n",
    "- rpy2 is a package to run R from Python\n",
    "- mro-base is Microsoft's R distribution\n",
    "- r-jsonlite and r-essentials are two conda packages which add the jsonlite package and a few other common packages to our R\n",
    "- azureml-monitoring is needed if you want to use AzureML's model data collection feature\n",
    "\n",
    "If you need more packages, you can specify them with the conda_packages parameter below - which should be the preferred method.\n",
    "\n",
    "However, if your packages are not available on conda, you can also tell the image_configuration() function below to add some local files or folders to the image (parameter: dependencies) and then install the packages manually by specifying some Docker commands in a file passed to the docker_file parameter. (The files/folders specified by dependencies parameter will be put into /var/azureml-app. The docker_file is run before the conda_packages. Hence you might to install some conda packages on your own if they are required by some commands in docker_file.)\n",
    "\n",
    "Another option would be to install additional packages within the R or Python code (in case the container will be connected to the required network). However in that case you may end up in unnecessary latencies. So installing all dependencies once in the image should always be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['rpy2', 'mro-base','r-jsonlite','r-essentials'])\n",
    "\n",
    "# only needed if the model data collection feature is used\n",
    "conda_dependencies.add_pip_package(\"azureml-monitoring\")\n",
    "\n",
    "with open(\"conda_dependencies.yml\",\"w\") as f:\n",
    "    f.write(conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the image (this might take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script=\"score.py\",\n",
    "    runtime=\"python\",\n",
    "    conda_file=\"conda_dependencies.yml\",\n",
    "    description=\n",
    "    \"Sample image to show the usage of R with Azure Machine Learning Services.\",\n",
    "    tags={\n",
    "        'area': \"samples\",\n",
    "        'type': \"regression\"\n",
    "    },\n",
    ")\n",
    "\n",
    "image = ContainerImage.create(name=\"r-on-amls-sample\",\n",
    "                              models=[model],\n",
    "                              image_config=image_config,\n",
    "                              workspace=workspace)\n",
    "\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "There is multiple engines where the image we created before could be deployed to. Select the one which is most appropriate for you.\n",
    "\n",
    "## Option 1: Deploy to ACI\n",
    "\n",
    "ACI is good for quick dev tests. It's not recommended for production workloads. For an SSL deployment to ACI, you need to bring your own SSL certificate (= different to AKS where Microsoft can provide certificates if desired). You can use the attached [PowerShell script](Create-SelfSignedCertificate.ps1) to create a self-signed certificate for inital testing purposes. The script will also install the certificate into the certificate store of your computer.\n",
    "\n",
    "Note however that webservice clients might not work with self-signed certificates, and they are not appropriate for production workloads. **When creating a certificate, you have to ensure that the DNS names match. Otherwise, the certificate validation will fail later.** Also keep in mind that certificates expire (depending on what you configured. usually, certificates expire after one year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "## configuration\n",
    "service_name = \"r-on-aml-service-aci\"\n",
    "deployment_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=2,\n",
    "    tags={\n",
    "        'area': \"samples\",\n",
    "        'type': \"regression\"\n",
    "    },\n",
    "    description=\n",
    "    'Sample image to show the usage of R with Azure Machine Learning Services.',\n",
    "    auth_enabled=True,\n",
    "\n",
    "    # note: - required if SSL is used, optional if SSL is not used\n",
    "    #       - GIVE IT TO YOUR OWN NAME BEFORE DEPLOYING!!!\n",
    "    #       - only lowercase letters, numbers and hyphens.\n",
    "    #         first character must be a letter.\n",
    "    #         last character must be a letter or number.\n",
    "    #         value must be between 5 and 63 characters long.\n",
    "    dns_name_label=\"fidge-my-new-aci-webservice\",\n",
    "\n",
    "    # SSL- comment/uncomment as needed\n",
    "    ssl_enabled=True,\n",
    "    ssl_cname=\"fidge-my-new-aci-webservice.westeurope.azurecontainer.io\",\n",
    "    ssl_cert_pem_file=\"certificate_for_amls.pem\",\n",
    "    ssl_key_pem_file=\"private_key_for_amls.pem\")\n",
    "\n",
    "## do deployment\n",
    "aci_service = Webservice.deploy_from_image(workspace=workspace,\n",
    "                                           name=\"r-on-aml-service-aci\",\n",
    "                                           deployment_config=deployment_config,\n",
    "                                           image=image)\n",
    "aci_service.wait_for_deployment(show_output=True)\n",
    "\n",
    "# inform about URIs and auth\n",
    "print(\"Scoring URI: {}\".format(aci_service.scoring_uri))\n",
    "print(\"Swagger URI: {}\".format(aci_service.swagger_uri))\n",
    "print(\"Auth Keys: {}\".format(aci_service.get_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Deploy to existing AKS (Kubernetes)\n",
    "\n",
    "AKS should be used for production workloads. Note that for AKS, SSL encryption is configured at the AKS cluster. Besides, the model data collection feature is only supported on AKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ComputeTarget\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "\n",
    "aks_cluster_name = \"aks-cluster\"\n",
    "aks_service_name = 'r-on-aml-service-aks'\n",
    "collect_model_data = True\n",
    "enable_app_insights = True\n",
    "\n",
    "# deploy webservice\n",
    "aks_service_list = [webservice for webservice in AksWebservice.list(workspace) if webservice.name == aks_service_name]\n",
    "aks_service = aks_service_list[0] if len(aks_service_list) == 1 else None\n",
    "if aks_service:   \n",
    "    print(\"Updating existing service...\")\n",
    "    aks_service.update(image=image,\n",
    "                       enable_app_insights=enable_app_insights,\n",
    "                       collect_model_data=collect_model_data)\n",
    "    print(\"Update completed.\")\n",
    "\n",
    "else:\n",
    "    print(\"Deploying new webservice...\")\n",
    "    aks_service = Webservice.deploy_from_image(workspace=workspace,\n",
    "                                                   name=aks_service_name,\n",
    "                                                   image=image,\n",
    "                                                   deployment_config=AksWebservice.deploy_configuration(\n",
    "                                                       collect_model_data=collect_model_data,\n",
    "                                                       enable_app_insights=enable_app_insights\n",
    "                                                   ),\n",
    "                                                   deployment_target=ComputeTarget(\n",
    "                                                       workspace=workspace,\n",
    "                                                       name=aks_cluster_name))\n",
    "    aks_service.wait_for_deployment(show_output=True)\n",
    "    print(\"Creation completed.\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Scoring URI: {}\".format(aks_service.scoring_uri))\n",
    "print(\"Swagger URI: {}\".format(aks_service.swagger_uri))\n",
    "print(\"Keys: {}\".format(aks_service.get_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Deploy to Azure Web Apps for Containers\n",
    "\n",
    "This option is currently in preview. See [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-app-service) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the web service\n",
    "To test the webservice, use the accompanying [Consume Webservice](consume-webservice.ipynb) notebook. Use the scoring URI and one of the keys printed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Don't forget to clean up the resources you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if aci_service:\n",
    "#    aci_service.delete()\n",
    "#if aks_service:\n",
    "#    aks_service.delete()\n",
    "#image.delete()\n",
    "#model.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "raymondl"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
